{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyguozz/CNN-for-Classification-using-the-Fashion-MNIST-dataset/blob/main/LeNet5_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYfn2AKlsPD-"
      },
      "source": [
        "# Implementation of LeNet-5 Using Keras\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0KWSxe1t-qv"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras import models, layers\n",
        "import keras\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from keras.utils import np_utils\n",
        "from keras.regularizers import l1, l2\n",
        "import keras.backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTut70eEa_dj"
      },
      "source": [
        "## Download Data Set & Normalize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQE2X4u5pgrq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a15c5835-a0c8-459f-bb64-2d28050a5acd"
      },
      "source": [
        "# Load dataset as train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "# Normalize value to [0, 1]\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Transform lables to one-hot encoding\n",
        "y_train = np_utils.to_categorical(y_train, 10)\n",
        "y_test = np_utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Reshape the dataset into 4D array\n",
        "x_train = x_train.reshape(x_train.shape[0], 28,28,1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28,28,1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94pOkgRS6FSo",
        "outputId": "5e9177e7-e1bc-4c0d-ba45-a780fcdf3d5f"
      },
      "source": [
        "print(' Size of x_train: ',x_train.shape, '\\n', 'Size of x_test: ',  x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Size of x_train:  (60000, 28, 28, 1) \n",
            " Size of x_test:  (10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy84bwo1qO60"
      },
      "source": [
        "BATCHSIZE = 128\n",
        "EPOCH = 15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADY6HskksIuz"
      },
      "source": [
        "## Q1 : Define LeNet-5 Model:   Baseline Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTDMkmKdp8EI"
      },
      "source": [
        "def model_baseline():\n",
        "    #Instantiate an empty model\n",
        "    model = Sequential()\n",
        "\n",
        "    # Convolutional Layer: Conv1(f=5, s=1) 6 filters\n",
        "    model.add(layers.Conv2D(6, kernel_size=(5, 5), strides=(1, 1), activation='relu', \n",
        "                            input_shape=(28,28,1), padding='valid'))\n",
        "    # Pooling Layer: Pool1 (2*2, s=2)\n",
        "    model.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "    # Convolutional Layer: Conv2(f=5, s=1) 16 filters\n",
        "    model.add(layers.Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='relu', padding='valid'))\n",
        "    # Pooling Layer: Pool2 (2*2, s=2)\n",
        "    model.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "    # Fully connected layers \n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(120, activation='relu'))\n",
        "    model.add(layers.Dense(84, activation='relu'))\n",
        "    #Output Layer\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer='SGD', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rY6BgXJ17Pp"
      },
      "source": [
        "## Q2:  Add L2 weight decay regularization\n",
        "## Q3:  Add L1 weight decay regularization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7v_jcvHLatnD"
      },
      "source": [
        "# Using kernel_regularizer\n",
        "# parameter lamda: regularization strengths, such as, 1e-4, 1e-3\n",
        "# reg_type = 1: L1 regularization\n",
        "# reg_type = 2: L2 regularization\n",
        "def model_reg( reg_type = 1, lamda = 1e-3 ):   \n",
        "    if reg_type == 1:\n",
        "        reg = l1(lamda)\n",
        "    else:\n",
        "        reg = l2(lamda)\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(layers.Conv2D(6, kernel_size=(5, 5), strides=(1, 1), \n",
        "                            activation='relu', input_shape=(28,28,1), padding='valid',\n",
        "                            kernel_regularizer = reg ))\n",
        "    model.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='relu', padding='valid', kernel_regularizer = reg))\n",
        "    model.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(120, activation='relu',kernel_regularizer = reg))\n",
        "    model.add(layers.Dense(84, activation='relu',kernel_regularizer = reg))\n",
        "    model.add(layers.Dense(10, activation='softmax',kernel_regularizer = reg))\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer='SGD', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agIf2enjFSRE"
      },
      "source": [
        "## Q4: Global Average Pooling "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQuM_omUN_IE"
      },
      "source": [
        "# Q4: Global Average Pooling \n",
        "def model_GAP():\n",
        "    model = Sequential()\n",
        "    model.add(layers.Conv2D(6, kernel_size=(5, 5), strides=(1, 1), \n",
        "                            activation='relu', input_shape=(28,28,1), padding='valid'))\n",
        "    model.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='relu', padding='valid'))\n",
        "    model.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.GlobalAveragePooling2D())\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer='SGD', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjHtWKsWYZX3"
      },
      "source": [
        "## Question 4:\n",
        "## Calculate the number parameters in model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHPksqZMQOp0"
      },
      "source": [
        "# Calculate the number of model for Question 4.\n",
        "def model_size(model): # Compute number of params in a model (the actual number of floats)\n",
        "    return sum([np.prod(K.get_value(w).shape) for w in model.trainable_weights])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKzzhU6vdXN0"
      },
      "source": [
        "## Question 6:\n",
        "## Analyze the weights of the regularized models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofwK2NbQ82SE"
      },
      "source": [
        "# Question 6:\n",
        "# Analyze the weights of the regularized models\n",
        "# Hoyer_index\n",
        "def Hoyer_index(w_fc):\n",
        "    sum_cj = tf.reduce_sum(tf.abs(w_fc)) \n",
        "    sqrt_sumsquare_cj = tf.sqrt(tf.reduce_sum(tf.square(w_fc))) \n",
        "    # Number of elements of FC layer\n",
        "    N = int(tf.size(w_fc)) \n",
        "    # Hoyer's index\n",
        "    return ((np.sqrt(N) - sum_cj/ sqrt_sumsquare_cj)*(1/(np.sqrt(N)-1)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4YMWYc3dd39"
      },
      "source": [
        "## Question 5:  Train/test models three times\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4kmo56kq7Ng"
      },
      "source": [
        "# define function to call different models\n",
        "def run3(model_type = 1, reg = 1, lamda = 1e-3):\n",
        "    Train_loss = []\n",
        "    Test_loss = []\n",
        "    Time_cost = []\n",
        "    Train_acc = []\n",
        "    Test_acc = []\n",
        "    for k in range(3):\n",
        "        if model_type == 1:\n",
        "            model = model_baseline()\n",
        "        elif model_type == 2:\n",
        "            model = model_reg(reg, lamda)\n",
        "        else:\n",
        "            model = model_GAP()\n",
        "        \n",
        "        start_time = time.time()\n",
        "        with tf.device('/device:GPU:0'):\n",
        "            hist = model.fit(x = x_train,y = y_train, epochs= EPOCH, batch_size=BATCHSIZE, validation_split = 0.15,\n",
        "                            verbose=0) \n",
        "        end_time = time.time()\n",
        "        Train_loss.append(hist.history['loss'][-1])\n",
        "        Train_acc.append(hist.history['accuracy'][-1])\n",
        "        Time_cost.append(end_time - start_time)\n",
        "        # test the model \n",
        "        test_score = model.evaluate(x_test, y_test)\n",
        "        Test_loss.append(test_score[0])\n",
        "        Test_acc.append(test_score[1])\n",
        "    print(model.summary())        \n",
        "    if (model_type != 3):\n",
        "        print('--- Sparsity measurements ---')        \n",
        "        # FC layer 1\n",
        "        Hoyer_layer1 = Hoyer_index(model.layers[5].get_weights()[0])  \n",
        "        # FC layer 2\n",
        "        Hoyer_layer2 = Hoyer_index(model.layers[6].get_weights()[0])\n",
        "        print('Hoyer_layer1:',float(Hoyer_layer1), '  Hoyer_layer2:', float(Hoyer_layer2),'\\n')\n",
        "    \n",
        "    print('--- Time cost ---')\n",
        "    print('Time_cost:      %.2f, %.2f, %.2f' % (float(Time_cost[0]) , float(Time_cost[1]), float(Time_cost[2])))\n",
        "    print('Mean_Time_cost:', np.mean(Time_cost), '(+/-',np.std(Time_cost),')\\n')\n",
        "    print('-- Train error,  Test error --')\n",
        "    print('Train_error: ', Train_loss[0] , Train_loss[1],Train_loss[2])\n",
        "    print('Mean_Train_error:', np.mean(Train_loss), '(+/-',np.std(Train_loss),')\\n')\n",
        "\n",
        "    print('Test_error :   ', Test_loss[0] , Test_loss[1], Test_loss[2])\n",
        "    print('Mean_Test_error:', np.mean(Test_loss), '(+/-',np.std(Test_loss),')\\n')\n",
        "    print('-- Train accuracy,  Test accuracy --')\n",
        "    print('Train_acc:  ' , Train_acc[0] , Train_acc[1], Train_acc[2])\n",
        "    print('Mean_Train_acc:', np.mean(Train_acc), '(+/-',np.std(Train_acc),')\\n')\n",
        "    print('Test_acc:   ' , Test_acc[0] ,Test_acc[1], Test_acc[2])\n",
        "    print('Mean_Test_acc:', np.mean(Test_acc), '(+/-',np.std(Test_acc),')')\n",
        "\n",
        "    # Question 4: calculate the number of parameters for this model\n",
        "    Model_Size= model_size(model)\n",
        "\n",
        "    return Model_Size\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwOqSNjrfQaj"
      },
      "source": [
        "## Question 5: Train/test models three times\n",
        "## Output the results for Q4, Q5, Q6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baQDLCL1JKFW",
        "outputId": "b149d7b1-f73a-40fe-8e6f-a890547b1d9f"
      },
      "source": [
        "# Question 5: Train/test models three times\n",
        "print('\\n================ Baseline model ================\\n')\n",
        "model_id = 1 # baseline model\n",
        "Num_para_baseline = run3(model_type = model_id)\n",
        "\n",
        "# Add L2 weight decay regularization\n",
        "print('\\n =============== L2, weight_decay = 1e-3 ===============\\n')\n",
        "model_id = 2 # model with L1 or L2 \n",
        "# set regularization parameters\n",
        "regl_type = 2 # regularization type, 1: L1,  2: L2\n",
        "lamd = 1e-3   # regularization strength\n",
        "run3(model_id, regl_type, lamd) #\n",
        "\n",
        "print('\\n =============== L2, weight_decay = 1e-4 ===============\\n')\n",
        "model_id = 2 # model with L1 or L2 \n",
        "regl_type = 2 # regularization type, 1: L1,  2: L2\n",
        "lamd = 1e-4   # regularization strength\n",
        "run3(model_id, regl_type, lamd) #\n",
        "\n",
        "# Add L1 weight decay regularization\n",
        "print('\\n =============== L1, weight_decay = 1e-3 ===============\\n')\n",
        "model_id = 2 # model with L1 or L2 \n",
        "regl_type = 1 # regularization type, 1: L1,  2: L2\n",
        "lamd = 1e-3   # regularization strength\n",
        "run3(model_id, regl_type, lamd) #\n",
        "\n",
        "print('\\n =============== L1, weight_decay = 1e-4 ===============\\n')\n",
        "model_id = 2 # model with L1 or L2 \n",
        "regl_type = 1 # regularization type, 1: L1,  2: L2\n",
        "lamd = 1e-4   # regularization strength\n",
        "run3(model_id, regl_type, lamd) #\n",
        "\n",
        "# Q4: model with Global Average Pooling\n",
        "print('\\n =============== Q4: model with Global Average Pooling ===============\\n')\n",
        "model_id = 3 # model with Global Average Pooling\n",
        "Num_para_GAP = run3(model_id)\n",
        "print('\\n=============== Question 4 ===============\\n')\n",
        "diff_num_para = Num_para_baseline - Num_para_GAP\n",
        "print('Number of parameters in Baseline model:  ', Num_para_baseline  )\n",
        "print('Number of parameters in GAP model:  ', Num_para_GAP  )\n",
        "print('The difference of number of parameters between Baseline model and the model using GAP: \\n', \\\n",
        "      diff_num_para)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "================ Baseline model ================\n",
            "\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.5347 - accuracy: 0.8042\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.5934 - accuracy: 0.7773\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4907 - accuracy: 0.8241\n",
            "Model: \"sequential_59\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_118 (Conv2D)          (None, 24, 24, 6)         156       \n",
            "_________________________________________________________________\n",
            "average_pooling2d_118 (Avera (None, 12, 12, 6)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_119 (Conv2D)          (None, 8, 8, 16)          2416      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_119 (Avera (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten_56 (Flatten)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_171 (Dense)            (None, 120)               30840     \n",
            "_________________________________________________________________\n",
            "dense_172 (Dense)            (None, 84)                10164     \n",
            "_________________________________________________________________\n",
            "dense_173 (Dense)            (None, 10)                850       \n",
            "=================================================================\n",
            "Total params: 44,426\n",
            "Trainable params: 44,426\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--- Sparsity measurements ---\n",
            "Hoyer_layer1: 0.13996046781539917   Hoyer_layer2: 0.13835680484771729 \n",
            "\n",
            "--- Time cost ---\n",
            "Time_cost:      16.51, 16.26, 16.46\n",
            "Mean_Time_cost: 16.40811785062154 (+/- 0.1081320183774551 )\n",
            "\n",
            "-- Train error,  Test error --\n",
            "Train_error:  0.47114506363868713 0.47321462631225586 0.46356791257858276\n",
            "Mean_Train_error: 0.46930920084317523 (+/- 0.004146690698040049 )\n",
            "\n",
            "Test_error :    0.5346907377243042 0.5934125781059265 0.49073007702827454\n",
            "Mean_Test_error: 0.5396111309528351 (+/- 0.042064091646225044 )\n",
            "\n",
            "-- Train accuracy,  Test accuracy --\n",
            "Train_acc:   0.8288038969039917 0.8269215822219849 0.8284117579460144\n",
            "Mean_Train_acc: 0.8280457456906637 (+/- 0.0008108640941714915 )\n",
            "\n",
            "Test_acc:    0.8041999936103821 0.7773000001907349 0.8241000175476074\n",
            "Mean_Test_acc: 0.8018666704495748 (+/- 0.019177134020849987 )\n",
            "\n",
            " =============== L2, weight_decay = 1e-3 ===============\n",
            "\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.7612 - accuracy: 0.8177\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.8419 - accuracy: 0.7712\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.7585 - accuracy: 0.8205\n",
            "Model: \"sequential_62\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_124 (Conv2D)          (None, 24, 24, 6)         156       \n",
            "_________________________________________________________________\n",
            "average_pooling2d_124 (Avera (None, 12, 12, 6)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_125 (Conv2D)          (None, 8, 8, 16)          2416      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_125 (Avera (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten_59 (Flatten)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_180 (Dense)            (None, 120)               30840     \n",
            "_________________________________________________________________\n",
            "dense_181 (Dense)            (None, 84)                10164     \n",
            "_________________________________________________________________\n",
            "dense_182 (Dense)            (None, 10)                850       \n",
            "=================================================================\n",
            "Total params: 44,426\n",
            "Trainable params: 44,426\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--- Sparsity measurements ---\n",
            "Hoyer_layer1: 0.14132986962795258   Hoyer_layer2: 0.13782933354377747 \n",
            "\n",
            "--- Time cost ---\n",
            "Time_cost:      18.04, 17.74, 17.80\n",
            "Mean_Time_cost: 17.861199617385864 (+/- 0.129822772494376 )\n",
            "\n",
            "-- Train error,  Test error --\n",
            "Train_error:  0.7335174083709717 0.7479004859924316 0.7348290681838989\n",
            "Mean_Train_error: 0.7387489875157675 (+/- 0.006493204455043894 )\n",
            "\n",
            "Test_error :    0.7611544728279114 0.8418974876403809 0.7585256099700928\n",
            "Mean_Test_error: 0.7871925234794617 (+/- 0.038697136482061086 )\n",
            "\n",
            "-- Train accuracy,  Test accuracy --\n",
            "Train_acc:   0.826764702796936 0.8199607729911804 0.8264706134796143\n",
            "Mean_Train_acc: 0.8243986964225769 (+/- 0.0031403816560883336 )\n",
            "\n",
            "Test_acc:    0.8177000284194946 0.7712000012397766 0.8205000162124634\n",
            "Mean_Test_acc: 0.8031333486239115 (+/- 0.02260920150848722 )\n",
            "\n",
            " =============== L2, weight_decay = 1e-4 ===============\n",
            "\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.5634 - accuracy: 0.8047\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.5329 - accuracy: 0.8180\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.5324 - accuracy: 0.8185\n",
            "Model: \"sequential_65\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_130 (Conv2D)          (None, 24, 24, 6)         156       \n",
            "_________________________________________________________________\n",
            "average_pooling2d_130 (Avera (None, 12, 12, 6)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_131 (Conv2D)          (None, 8, 8, 16)          2416      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_131 (Avera (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten_62 (Flatten)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_189 (Dense)            (None, 120)               30840     \n",
            "_________________________________________________________________\n",
            "dense_190 (Dense)            (None, 84)                10164     \n",
            "_________________________________________________________________\n",
            "dense_191 (Dense)            (None, 10)                850       \n",
            "=================================================================\n",
            "Total params: 44,426\n",
            "Trainable params: 44,426\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--- Sparsity measurements ---\n",
            "Hoyer_layer1: 0.13889463245868683   Hoyer_layer2: 0.14008493721485138 \n",
            "\n",
            "--- Time cost ---\n",
            "Time_cost:      17.99, 17.24, 17.71\n",
            "Mean_Time_cost: 17.64442976315816 (+/- 0.3103274549478667 )\n",
            "\n",
            "-- Train error,  Test error --\n",
            "Train_error:  0.5251510143280029 0.5050865411758423 0.49344733357429504\n",
            "Mean_Train_error: 0.5078949630260468 (+/- 0.013094433125054488 )\n",
            "\n",
            "Test_error :    0.5633646249771118 0.5329031944274902 0.5323634147644043\n",
            "Mean_Test_error: 0.5428770780563354 (+/- 0.014488559271471869 )\n",
            "\n",
            "-- Train accuracy,  Test accuracy --\n",
            "Train_acc:   0.8181568384170532 0.8268627524375916 0.8291960954666138\n",
            "Mean_Train_acc: 0.8247385621070862 (+/- 0.004750469273080814 )\n",
            "\n",
            "Test_acc:    0.8047000169754028 0.8180000185966492 0.8184999823570251\n",
            "Mean_Test_acc: 0.8137333393096924 (+/- 0.006390783741023899 )\n",
            "\n",
            " =============== L1, weight_decay = 1e-3 ===============\n",
            "\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 1.7912 - accuracy: 0.7729\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 1.8687 - accuracy: 0.7415\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 1.7787 - accuracy: 0.7561\n",
            "Model: \"sequential_68\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_136 (Conv2D)          (None, 24, 24, 6)         156       \n",
            "_________________________________________________________________\n",
            "average_pooling2d_136 (Avera (None, 12, 12, 6)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_137 (Conv2D)          (None, 8, 8, 16)          2416      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_137 (Avera (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten_65 (Flatten)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_198 (Dense)            (None, 120)               30840     \n",
            "_________________________________________________________________\n",
            "dense_199 (Dense)            (None, 84)                10164     \n",
            "_________________________________________________________________\n",
            "dense_200 (Dense)            (None, 10)                850       \n",
            "=================================================================\n",
            "Total params: 44,426\n",
            "Trainable params: 44,426\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--- Sparsity measurements ---\n",
            "Hoyer_layer1: 0.38590043783187866   Hoyer_layer2: 0.3092772364616394 \n",
            "\n",
            "--- Time cost ---\n",
            "Time_cost:      18.39, 17.98, 17.92\n",
            "Mean_Time_cost: 18.09588138262431 (+/- 0.21213879144737324 )\n",
            "\n",
            "-- Train error,  Test error --\n",
            "Train_error:  1.7810876369476318 1.7973840236663818 1.773817539215088\n",
            "Mean_Train_error: 1.784096399943034 (+/- 0.009853401728003894 )\n",
            "\n",
            "Test_error :    1.791211724281311 1.8686972856521606 1.7787400484085083\n",
            "Mean_Test_error: 1.8128830194473267 (+/- 0.03979371733290837 )\n",
            "\n",
            "-- Train accuracy,  Test accuracy --\n",
            "Train_acc:   0.8005490303039551 0.7928431630134583 0.7918431162834167\n",
            "Mean_Train_acc: 0.79507843653361 (+/- 0.0038897789582160278 )\n",
            "\n",
            "Test_acc:    0.7728999853134155 0.7415000200271606 0.7560999989509583\n",
            "Mean_Test_acc: 0.7568333347638448 (+/- 0.012829465851581647 )\n",
            "\n",
            " =============== L1, weight_decay = 1e-4 ===============\n",
            "\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.8134 - accuracy: 0.8131\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.8346 - accuracy: 0.7972\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.7916 - accuracy: 0.8214\n",
            "Model: \"sequential_71\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_142 (Conv2D)          (None, 24, 24, 6)         156       \n",
            "_________________________________________________________________\n",
            "average_pooling2d_142 (Avera (None, 12, 12, 6)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_143 (Conv2D)          (None, 8, 8, 16)          2416      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_143 (Avera (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten_68 (Flatten)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_207 (Dense)            (None, 120)               30840     \n",
            "_________________________________________________________________\n",
            "dense_208 (Dense)            (None, 84)                10164     \n",
            "_________________________________________________________________\n",
            "dense_209 (Dense)            (None, 10)                850       \n",
            "=================================================================\n",
            "Total params: 44,426\n",
            "Trainable params: 44,426\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--- Sparsity measurements ---\n",
            "Hoyer_layer1: 0.16044433414936066   Hoyer_layer2: 0.15691126883029938 \n",
            "\n",
            "--- Time cost ---\n",
            "Time_cost:      17.78, 17.86, 17.89\n",
            "Mean_Time_cost: 17.845328728357952 (+/- 0.046135455376339785 )\n",
            "\n",
            "-- Train error,  Test error --\n",
            "Train_error:  0.7671554088592529 0.7679958343505859 0.760743260383606\n",
            "Mean_Train_error: 0.7652981678644816 (+/- 0.003239029213732957 )\n",
            "\n",
            "Test_error :    0.8133793473243713 0.8346347808837891 0.7915669083595276\n",
            "Mean_Test_error: 0.813193678855896 (+/- 0.017582875485855524 )\n",
            "\n",
            "-- Train accuracy,  Test accuracy --\n",
            "Train_acc:   0.8224117755889893 0.8237646818161011 0.8268431425094604\n",
            "Mean_Train_acc: 0.8243398666381836 (+/- 0.0018542530177274724 )\n",
            "\n",
            "Test_acc:    0.8130999803543091 0.7972000241279602 0.821399986743927\n",
            "Mean_Test_acc: 0.8105666637420654 (+/- 0.010040677847202344 )\n",
            "\n",
            " =============== Q4: model with Global Average Pooling ===============\n",
            "\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.8072 - accuracy: 0.6850\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.7909 - accuracy: 0.7121\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.8323 - accuracy: 0.6637\n",
            "Model: \"sequential_74\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_148 (Conv2D)          (None, 24, 24, 6)         156       \n",
            "_________________________________________________________________\n",
            "average_pooling2d_148 (Avera (None, 12, 12, 6)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_149 (Conv2D)          (None, 8, 8, 16)          2416      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_149 (Avera (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_5 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_212 (Dense)            (None, 10)                170       \n",
            "=================================================================\n",
            "Total params: 2,742\n",
            "Trainable params: 2,742\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--- Time cost ---\n",
            "Time_cost:      16.02, 15.82, 16.36\n",
            "Mean_Time_cost: 16.068036476771038 (+/- 0.22489232913783158 )\n",
            "\n",
            "-- Train error,  Test error --\n",
            "Train_error:  0.7689048051834106 0.7898388504981995 0.7869958877563477\n",
            "Mean_Train_error: 0.781913181145986 (+/- 0.009271245625612884 )\n",
            "\n",
            "Test_error :    0.8072376847267151 0.7909481525421143 0.8323231339454651\n",
            "Mean_Test_error: 0.8101696570714315 (+/- 0.017018022170717392 )\n",
            "\n",
            "-- Train accuracy,  Test accuracy --\n",
            "Train_acc:   0.713039219379425 0.706352949142456 0.704235315322876\n",
            "Mean_Train_acc: 0.7078758279482523 (+/- 0.0037520262572009445 )\n",
            "\n",
            "Test_acc:    0.6850000023841858 0.7121000289916992 0.6636999845504761\n",
            "Mean_Test_acc: 0.6869333386421204 (+/- 0.019806470614301398 )\n",
            "\n",
            "=============== Question 4 ===============\n",
            "\n",
            "Number of parameters in Baseline model:   44426\n",
            "Number of parameters in GAP model:   2742\n",
            "The difference of number of parameters between Baseline model and the model using GAP: \n",
            " 41684\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2QA7Tebrw0B"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}